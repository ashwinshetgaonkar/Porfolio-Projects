
# [1.Quotes Scraper](https://github.com/ashwinshetgaonkar/Web-Quotes-Scraper)
* Web scraping or web data extraction is data scraping used for extracting data from websites,this involves fetching data and extracting/parsing required info from it. Fetching is the downloading of a page (which a browser does when a user views a page).
* My objective for doing this project was to learn and implement web scraping on static sites.
* In this I have used requests and BeautifulSoup libraries to perform the web scraping.
* The project involves extracting the names of all topics of quotes and then scraping quotes along with their author name for all topics
  previously scraped.<br>
  [To view the web app](https://share.streamlit.io/ashwinshetgaonkar/web-quotes-scraper/main/app.py)

  



# [2.IPL Batting Analysis 2008-2021](https://github.com/ashwinshetgaonkar/Data-Visualization-Projects/tree/main/IPL%20Batting%20Analysis%202008-2021)                                      
 
* The Indian Premier League is a professional men's Twenty20 cricket league, contested by ten teams based out of ten Indian cities.The league was founded by the Board of Control for Cricket in India in 2007.
* The Dataset contains the stats of all the batsman to have played the league from 2008 upto 2021.
My objective for this Project was to unearth various useful insights from the available data that would help teams owners / people playing fantacy games get information about players that are leading in various batting stats like :
1. Players with max Strike Rate.
2. Players with least balls/boundary.
3. Players with most runs per season and many more.<br>
* Around 35 of such criterions are used to visualize the data which will give almost all the key attributes of batting.<br>
  [To view on kaggle](https://www.kaggle.com/code/ashwinshetgaonkar/ipl-batting-analysis-2008-2021)
  


# [3.Super Store Analysis](https://github.com/ashwinshetgaonkar/Data-Visualization-Projects/tree/main/Super%20Store%20Analysis)
* Competition in the retail industry is rising day by day. In a marketplace thatâ€™s becoming increasingly digital, retailers are compelled to use advanced analytics to ensure their business survives the competition. Before using analytics to evaluate store performance, 
it is necessary to identify the objectives behind adopting it. This ensures that the derived intelligence is effectively acted upon.
* Dataset contains Information related to Sales, Profits and other interesting facts of a Superstore giant.
* My objective for this Project was to translate the Data into a visual context so that if I was the owner of the Store I will be able to easily
understanding the Market demands and Customer behaviour which will intern help me in making decision like:
1. How much discounts to offer and for what products.
2. When to offer and in which regions to offer.
3. Make customized policies for customers of various segments and many more.<br>
   [To view on kaggle](https://www.kaggle.com/code/ashwinshetgaonkar/super-store-analysis-data-visual-seaborn) 
   


# [4.Road Deaths Analysis](https://github.com/ashwinshetgaonkar/Data-Visualization-Projects/tree/main/Road%20Deaths%20Analysis)
* The Dataset contains information of number of deaths in various regions of the World from 1990-2019,along with other data like historical population,region code,Side of driving.

* My objective for this Project was to visualize the available data to draw insights from it which are not perceived just by reading through an excel/csv file.
* Here I have visualized the number of deaths using various plots to gain various insights from the data.
* From this I can easily state the regions with maximum,mean deaths,year in which max deaths occured and many more.<br>
  [To view on kaggle](https://www.kaggle.com/code/ashwinshetgaonkar/road-deaths-data-visualization-seaborn)
  


# [5.Estimating Mechanical Properties of Steels](https://github.com/ashwinshetgaonkar/Estimate-Mechanical-Properties-of-Steel-compostions)
* Since currently there are no precise theoretical methods to predict mechanical properties of steels,I have made an attempt to predict the mechanical properties of steels using Maching Learning.
* The dataset contains compositions by weight percentages of low-alloy steels along with the temperatures at which the steels were tested and the values mechanical properties observed during the tests. 
* My aim for this Project is to analyse and transform the available data to make it fit to be used for model training and to use this data for building a model that accurately predicts the mechanical properties of steels.
* I have completed the above task using varing transformation methods and LightGBM for model training,Optuna for hyperparameter tunning.<br>
  [To view on kaggle](https://www.kaggle.com/code/ashwinshetgaonkar/mech-prop-lightgbm-optuna),[To view the web app](https://share.streamlit.io/ashwinshetgaonkar/estimate-mechanical-properties-of-steel-compostions/main/app.py)
 

# [6.Fake News Classifier](https://github.com/ashwinshetgaonkar/Fake-News-Classifier)
* In today's world which contains a lot of digital data it will be very beneficial to have some kind of an software that will help us in descriminating between Fake and Real News with some given constraints.
* The dataset contains news instances with title and text along with its labels taken from various sources.
* My objective for this project was to train and compare the performance of various models on the basis of f1_score and time taken per prediction.
* Here I have demostrated how increasing the complexity of the model will lead to better performance but will hamper the time taken per prediction.
* Build an web app using streamlit which uses model trained using a feed forward neutral network.<br>
  [To view on kaggle](https://www.kaggle.com/code/ashwinshetgaonkar/fake-news-classifier-nb-bert),[To view the web app](https://share.streamlit.io/ashwinshetgaonkar/fake-news-classifier/main/app.py)
  
  
  
# [7.Vegetable Classifier](https://github.com/ashwinshetgaonkar/Vegetable-Classifier)
* From vegetable production to delivery, several common steps are done manually like picking, and sorting vegetables.
* Therefore, it would be a great idea to automate this process in the coming future by using a robot empowering it using Computer Vision.
* The dataset consists of training/validation/test sets of images of 15 different vegetables.
* My aim for this Project was to build a classification model that could provide every high accuracy greater than 95%.
* By using suitable augmentation layer and callbacks functions on pretained model(efficientnetB0), I managed to get an accuracy above 99%.
* I have further analysed and visualized the performance of the model.
  [To view on kaggle](https://www.kaggle.com/code/ashwinshetgaonkar/vegetable-clf-transfer-learning-error-analysis)

